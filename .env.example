# LLM API Configuration
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# SiliconFlow Configuration
SILICONFLOW_API_KEY=your_siliconflow_api_key_here
SILICONFLOW_API_ENDPOINT=https://api.siliconflow.cn/v1/chat/completions
SILICONFLOW_MODEL=Qwen/Qwen3-Coder-30B-A3B-Instruct

# Default LLM Provider (openai, anthropic, or siliconflow)
DEFAULT_LLM_PROVIDER=siliconflow
DEFAULT_MODEL=deepseek-ai/DeepSeek-V3.2-Exp

# Default code LLM Provider (openai, anthropic, or siliconflow)
CODE_LLM_PROVIDER=siliconflow
CODE_LLM_MODEL=Qwen/Qwen3-Coder-30B-A3B-Instruct

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Workspace Configuration
WORKSPACE_ROOT=./workspaces

# Sandbox Configuration
SANDBOX_TIMEOUT=300
SANDBOX_MAX_MEMORY_MB=2048
SANDBOX_MAX_CPU_PERCENT=80

# Security
SECRET_KEY=your-secret-key-change-this-in-production

# LLM Token Limits
LLM_MAX_TOKENS=143840
LLM_CODE_MAX_TOKENS=10240
